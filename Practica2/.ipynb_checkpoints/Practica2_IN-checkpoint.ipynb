{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89519\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ismael/anaconda3/envs/IN_/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: This pattern has match groups. To actually get the groups, use str.extract.\n",
      "/home/ismael/anaconda3/envs/IN_/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colisión accidentes:  3222\n",
      "Colisión accidentes:  169\n",
      "Colisión accidentes:  3334\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-1223bc71ca18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# ('MeanShift',ms)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'DBSCAN'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdbscan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Birch'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbirch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'SpectralClustering'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mspectral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0;34m'Ward'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import cluster\n",
    "from sklearn import metrics\n",
    "from sklearn import preprocessing\n",
    "from math import floor\n",
    "\n",
    "\n",
    "#Activar para relizar pruebas con menos Datos\n",
    "prueba = False\n",
    "\n",
    "\n",
    "\n",
    "accidentes = pd.read_csv('accidentes_2013.csv')\n",
    "\n",
    "if(prueba):\n",
    "    accidentes = accidentes.sample(len(accidentes)//10)\n",
    "    print(len(accidentes))\n",
    "else:\n",
    "    print(len(accidentes))\n",
    "\n",
    "\n",
    "#seleccionar accidentes de tipo 'colisión de vehículos'\n",
    "subset1 = accidentes[accidentes['TIPO_ACCIDENTE'].str.contains(\"Colisión de vehículos\")]\n",
    "subset1 = subset1[accidentes['TIPO_ACCIDENTE'].str.contains(\"(Alcance)\") & (accidentes['TIPO_VIA'].str.contains(\"AUTOPISTA\") | accidentes['TIPO_VIA'].str.contains(\"AUTOVÍA\"))]\n",
    "caso_estudio1 = ['HORA', 'DIASEMANA', 'TOT_VICTIMAS']\n",
    "X1 = subset1[caso_estudio1]\n",
    "print('Colisión accidentes: ',len(X1))\n",
    "subset2 = accidentes[accidentes['TIPO_ACCIDENTE'].str.contains(\"Atropello\")& accidentes['PROVINCIA'].str.contains(\"Córdoba\")]\n",
    "\n",
    "caso_estudio2 = ['MES', 'DIASEMANA','HORA', 'TOT_MUERTOS']\n",
    "X2 = subset2[caso_estudio2]\n",
    "print('Colisión accidentes: ',len(X2))\n",
    "subset3 = accidentes[accidentes['TIPO_ACCIDENTE'].str.contains(\"Vuelco en la calzada\")]\n",
    "caso_estudio3 = ['TOT_HERIDOS_GRAVES', 'TOT_HERIDOS_LEVES', 'TOT_VEHICULOS_IMPLICADOS']\n",
    "X3 = subset3[caso_estudio3]\n",
    "print('Colisión accidentes: ',len(X3))\n",
    "\n",
    "usadas = [caso_estudio1,caso_estudio2,caso_estudio3]\n",
    "casos_de_estudio = [X1]\n",
    "\n",
    "k_means = cluster.KMeans(init='k-means++',n_clusters=4, n_init=5)\n",
    "mbkm = cluster.MiniBatchKMeans(n_clusters=4)\n",
    "ms = cluster.MeanShift()\n",
    "spectral = cluster.SpectralClustering(n_clusters=4)\n",
    "affinity_propagation = cluster.AffinityPropagation()\n",
    "dbscan = cluster.DBSCAN(eps=0.1, min_samples=5 )\n",
    "birch = cluster.Birch(n_clusters=4,threshold=0.3)\n",
    "ward = cluster.AgglomerativeClustering(n_clusters=4, linkage='ward')\n",
    "\n",
    "clustering_algorithm = (\n",
    "    ('k-means',k_means),\n",
    "# #     ('MiniBatkMeans',mbkm),\n",
    "    # ('MeanShift',ms)\n",
    "    ('DBSCAN',dbscan),\n",
    "    ('Birch',birch),\n",
    "    ('SpectralClustering',spectral),\n",
    "    ('Ward',ward)\n",
    ")\n",
    "for i,X in enumerate(casos_de_estudio):\n",
    "    print(\"\\nCaso de estudio \"+str(i+1)+\":\\n\")\n",
    "    X_normal = preprocessing.normalize(X, norm='l2')\n",
    "\n",
    "    for j,q in enumerate(clustering_algorithm):\n",
    "\n",
    "        name,algorithm = q\n",
    "        print('{:19s}'.format(name),end='')\n",
    "        t = time.time()\n",
    "        cluster_predict = algorithm.fit_predict(X_normal)\n",
    "        # print('\\nprediccion: ',cluster_predict)\n",
    "        tiempo = time.time() - t\n",
    "        k = len(set(cluster_predict))\n",
    "        print(\": k: {:3.0f}, \".format(k),end='')\n",
    "        print(\"{:6.2f} segundos, \".format(tiempo),end='')\n",
    "\n",
    "        if(k>1) and (name is not 'Ward'):\n",
    "            metric_CH = metrics.calinski_harabaz_score(X_normal, cluster_predict)\n",
    "\n",
    "            metric_SH = metrics.silhouette_score(X_normal, cluster_predict,metric = 'euclidean',sample_size=floor(0.1*len(X)),random_state=123456)\n",
    "        else:\n",
    "            metric_CH = 0\n",
    "            metric_SH = 0\n",
    "        print(\"CH Index: {:8.9f}, \".format(metric_CH),end='')\n",
    "        print(\"SH: {:.5f}\".format(metric_SH))\n",
    "\n",
    "        #se convierte la asignación de clusters a DataFrame\n",
    "        clusters = pd.DataFrame(cluster_predict,index=X.index,columns=['cluster'])\n",
    "        # print('cluster: ',cluster)\n",
    "        #y se añade como columna a X\n",
    "\n",
    "        X_cluster = pd.concat([X, clusters], axis=1)\n",
    "        #Filtro quitando los elementos (outliers) que caen en clusters muy pequeños en el jerárquico\n",
    "        min_size = 3\n",
    "        X_filtrado = X_cluster[X_cluster.groupby('cluster').cluster.transform(len) > min_size]\n",
    "        k_filtrado = len(set(X_filtrado['cluster']))\n",
    "        print('k_filtrado: ',k_filtrado)\n",
    "        # print(\"De los {:.0f} clusters hay {:.0f} con más de {:.0f} elementos. Del total de {:.0f} elementos, se seleccionan {:.0f}\".format(k['Ward'],k_filtrado,min_size,len(X),len(X_filtrado)))\n",
    "\n",
    "        if(i==1):\n",
    "            _X_filtrado_sin = X_filtrado.drop('cluster', 1)\n",
    "            #Normalizo el conjunto filtrado\n",
    "            _X_filtrado_normal = preprocessing.normalize(_X_filtrado_sin, norm='l2')\n",
    "            #Ahora lo saco usando seaborn (que a su vez usa scipy) para incluir un heatmap\n",
    "            import seaborn as sns\n",
    "            _X_filtrado_normal_DF = pd.DataFrame(_X_filtrado_normal,index=_X_filtrado_sin.index,columns=usadas[i])\n",
    "            dend_plot = sns.clustermap(_X_filtrado_normal_DF, method='ward', col_cluster=False, figsize=(20,10), cmap=\"YlGnBu\")\n",
    "            dend_plot.savefig('imagenes/dendograma.png')\n",
    "\n",
    "        print(\"---------- Preparando el scatter matrix...\")\n",
    "        import seaborn as sns\n",
    "        sns.set()\n",
    "        variables = list(X_filtrado)\n",
    "        variables.remove('cluster')\n",
    "        sns_plot = sns.pairplot(X_filtrado, vars=variables, hue=\"cluster\", palette='Paired', plot_kws={\"s\": 25}, diag_kind=\"hist\") #en hue indicamos que la columna 'cluster' define los colores\n",
    "        sns_plot.fig.subplots_adjust(wspace=.03, hspace=.03);\n",
    "        sns_plot.savefig('imagenes/Caso_de_estudio_'+str(i)+'/'+clustering_algorithm[j][0]+\".png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IN_",
   "language": "python",
   "name": "in_"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
